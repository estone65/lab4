---
title: "Lab 04 - Visualizing spatial data”"
author: "Eric Stone"
date: "`r Sys.Date()`"
output: github_document
---

### Load packages and data

```{r load-packages, message = FALSE}
library(tidyverse) 
library(dsbox) 
data ("dennys")
data ("laquinta")
```

```{r load-data, message = FALSE}
states <- read_csv("data/states.csv")
```

### Exercise 1


> What are the dimensions of the Denny’s dataset? (Hint: Use inline R code and functions like nrow and ncol to compose your answer.) What does each row in the dataset represent? What are the variables?

```{r exercise-1}
number_of_rows <- nrow(dennys)
number_of_columns <- ncol(dennys)
print(paste("Number of rows:", number_of_rows))
print(paste("Number of columns:", number_of_columns))
colnames(dennys)
```

There are 1643 rows and 6 columns.  

The rows indicate the specific dennys establishment; the columns are the address, city, state, zip, longitude, and latitude.

### Exercise 2

```{r exercise-2}
number_of_rows <- nrow(laquinta)
number_of_columns <- ncol(laquinta)
print(paste("Number of rows:", number_of_rows))
print(paste("Number of columns:", number_of_columns))
colnames(laquinta)
```

> What are the dimensions of the La Quinta’s dataset? What does each row in the dataset represent? What are the variables?

There are 909 rows and 6 columns.  

The rows indicate the specific laquita establishment; the columns are the address, city, state, zip, longitude, and latitude.

### Exercise 3

```{r exercise-3}
# examined website and data sets
```

> Take a look at the websites that the data come from (linked above). Are there any La Quinta’s locations outside of the US? If so, which countries? What about Denny’s?

I saw no locations outside the US listed in the website http://njgeo.org/2014/01/30/mitch-hedberg-and-gis/

I also saw no Denny's that were outside the United States.

However, there are La Quinta locations outside the US. The problem seems to be that states are listed that aren't really states. The ones I detected were:
	
Aguascalientes (State = AG)
Medellin Colombia (State = ANT)
Richmond (State = BC)
Col Partido Iglesias Juarez (State = CH)
contiguo Mall Las Cascadas Tegucigalpa (State = FM)
Parque Industrial Interamerican Apodaca (State = NL)
Col. Centro Monterrey (State = NL)
Monterrey (State = NL)
Oshawa (State = ON)
San Jose Chiapa (State = PU)
Col. ReservaTerritorial Atlixcayotl San Puebla (State = PU)
Cancun (State = QR)
San Luis Potosi (State = SL)
Poza Rica (State = VE)

It's possible I missed one or two, but the point is that there are a bunch of these. The person who constructed this data set should be reprimanded.

### Exercise 4

```{r exercise-4}
# describe possible approaches
```

> Now take a look at the data. What would be some ways of determining whether or not either establishment has any locations outside the US using just the data (and not the websites). Don’t worry about whether you know how to implement this, just brainstorm some ideas. Write down at least one as your answer, but you’re welcomed to write down a few options too.

Well, I "brute forced" it, using my knowledge of state abbreviations. I just scrolled down until I got to a state abbreviation I wasn't familiar with. Typically there was only 1 instance of that abbreviation (three at most). 

In SPSS I would enter each of the 51 abbreviations as part of an if command, giving me a 1 if it matches and a 0 otherwise. The command would look something like:

Do if state eq (al or aq or az ....) <br>
Compute US = 1 <br>
Else <br>
Compute US = 0 <br>
End if 

I expect R could do something similar. That first command is tedious, though, with 51 states. Since these abbreviations are all listed in the 'states' data set, there is probably a way to use that data set in conjunction with the laquinta data set and simpler code.

### Exercise 5

> Find the Denny’s locations that are outside the US, if any. To do so, filter the Denny’s locations for observations where state is not in states$abbreviation. The code for this is given below. Note that the %in% operator matches the states listed in the state variable to those listed in states$abbreviation. The ! operator means not. Are there any Denny’s locations outside the US?

```{r exercise-5}
dennys  %>%
  filter(!(state %in% states$abbreviation))
```

Nope, no dennys outside the US -- at least not in this data set!  (And yes, this is much easier than what I did :)  )


### Exercise 6

> Add a country variable to the Denny’s dataset and set all observations equal to "United States". Remember, you can use the mutate function for adding a variable. Make sure to save the result of this as dn again so that the stored data frame contains the new variable going forward.

```{r exercise-6}
dennys_us <- dennys %>%
  mutate(country = "United States")
colnames(dennys_us)
```

It worked!
 

### Exercise 7

> Find the La Quinta locations that are outside the US, and figure out which country they are in. This might require some googling. Take notes, you will need to use this information in the next exercise.

```{r exercise-7}
laquinta_no_us <- laquinta %>% 
  filter(!(state %in% states$abbreviation))
laquinta_no_us %>%
  select(address, city, state) %>%
  print()
```

This seems to match perfectly what I came up with previously!  

AG = Mexico (AGUASCALIENTES)
QR = Mexico (Cancun)
CH = Mexico (Coahuila?)
NL = Mexico (NUEVO LEON)
ANT = Columnbia (Antioquia)
ON = Canada (Ontario)
VE = Mexico (Veracruz)
PU = Mexico (Pueblo)
SL = Mexico (SAN LUIS POTOSI)
FM = Honduras (Francisco Morazán)
BC = Canada (British Columnbia)


### Exercise 8

> Add a country variable to the La Quinta dataset. Use the case_when function to populate this variable. You’ll need to refer to your notes from Exercise 7 about which country the non-US locations are in. Here is some starter code to get you going:

```{r exercise-8}
laquinta_country <- laquinta %>% 
  mutate(country = case_when(
    state %in% state.abb ~ "United States",
    state %in% c("ON", "BC") ~ "Canada",
    state == "ANT" ~ "Colombia",
    state == "FM" ~ "Honduras",
    state %in% c("AG", "QR", "CH", "NL","VE", "PU","SL") ~ "Mexico"
  ))
```

This command worked well.


### Exercise 9

```{r exercise-9a}
laquinta_us <- laquinta_country %>% 
 filter(country == "United States")
state_freq_denny <- dennys_us %>%
  count(state)
print(state_freq_denny,  n = Inf)
```

```{r exercise-9b}
state_freq_laquinta <- laquinta_us %>%
    count(state)
print(state_freq_laquinta,  n = Inf)
```

```{r exercise-9c}
#the following was from chatgpt, as it was more helpful to see them together
state_freq_denny <- dennys_us %>%
  count(state) %>%
  rename(dennys_freq = n)

state_freq_laquinta <- laquinta_us %>%
  count(state) %>%
  rename(laquinta_freq = n)

combined_freq <- full_join(state_freq_denny, state_freq_laquinta, by = "state")

print(combined_freq, n = Inf)
```


> Which states have the most and fewest Denny’s locations? What about La Quinta? Is this surprising? Why or why not?

California has by far the most Denny's locations. Delaware has the fewest, but all small states had only a small number. All states had at least one.

Texas has the most La Quinta locations. Again, size of state is an important factor, but another important factor is whether the state is southern or not.  DC, Delaware, and Hawaii have no La Quintas. 
In general, the key difference is that there's a clear tendency for southern states to have more La Quinta locations, but not more Dennys locations. In retrospect, this isn't surprising at all given that states further south are more Spanish speaking, which is consistent with the name La Quinta. Furthermore, most of the non-US La Quintas are in Mexico, which is also consistent with this finding.



### Exercise 10

> Next, let’s calculate which states have the most Denny’s locations per thousand square miles. This requires joining information from the frequency tables you created in the previous set with information from the states data frame.

> First, we count how many observations are in each state, which will give us a data frame with two variables: state and n. Then, we join this data frame with the states data frame. However note that the variables in the states data frame that has the two-letter abbreviations is called abbreviation. So when we’re joining the two data frames we specify that the state variable from the Denny’s data should be matched by the abbreviation variable from the states data:

```{r exercise-10}
laquinta_us_with_area <- laquinta_us %>% 
  count(state) %>%
  inner_join(states, by = c("state" = "abbreviation")) %>%  
  mutate(location_per_thousand_miles = 1000 * n / area)
laquinta_us_with_area %>%
  select(state, location_per_thousand_miles) %>%
  print(n = Inf)
dennys_us_with_area <- dennys_us %>% 
  count(state) %>%
  inner_join(states, by = c("state" = "abbreviation")) %>% 
  mutate(location_per_thousand_miles = 1000 * n / area)
dennys_us_with_area %>%
  select(state, location_per_thousand_miles) %>%
  print(n = Inf)
```
> Before you move on the the next question, run the code above and take a look at the output. In the next exercise, you will need to build on this pipe.

> Which states have the most Denny’s locations per thousand square miles? What about La Quinta?

For Denny's it is by far and away DC.

For La Quinta, Rhode Island is tops, followed by Florida. 

Note that in general, the smallest states had the largest ratios.


### Practice at Mason's

this will combine and save -- it's not relevant to this assignment, so am commenting it out

```{r practice}
# laquinta_us <- laquinta_us %>% left_join(laquinta_us_with_area, by = c("state"))
```


### Exercise 11

> Next, we put the two datasets together into a single data frame. However before we do so, we need to add an identifier variable. We’ll call this establishment and set the value to "Denny's" and "La Quinta" for the dn and lq data frames, respectively.


```{r exercise-11a}
dennys_to_combine <- dennys_us %>%
   mutate(establishment = "Denny's")
laquinta_to_combine <- laquinta_us %>%
   mutate(establishment = "La Quinta")

dn_lq <- bind_rows(dennys_to_combine, laquinta_to_combine)
```

This worked well. It's basically what I did before, but using data sets that actually have latitude and longitude in them.... :)


```{r exercise-11b}
ggplot(dn_lq, mapping = aes(
   x = longitude,
   y = latitude,
   color = establishment
 )) +
   geom_point()
```



And now this works, since latitude and longitude exist.

> Filter the data for observations in North Carolina only, and recreate the plot. You should also adjust the transparency of the points, by setting the alpha level, so that it’s easier to see the overplotted ones. Visually, does Mitch Hedberg’s joke appear to hold here?

```{r exercise-11c}
dn_lq %>% 
   filter(state == "NC") %>%
   ggplot(mapping = aes(
   x = longitude,
   y = latitude,
   color = establishment
 )) +
   geom_point(size = 1, alpha = 0.4) + 
   labs(title = "Location of Dennys vs Laquinta in North Carolina")
```

Not really.  Although it is true that most of the Laquintas have Dennys near them, they don't seem to be super close. Further, I expect the intermediate closeness is just a function of population. Big cities have both Dennys and Laquintas, while rural areas have neither. To really evaluate this question, I think you need to use other food chains, and see if they cluster further from Laquintas than Dennys does. If they do, I would start to be convinced.


> Now filter the data for observations in Texas only, and recreate the plot, with an appropriate alpha level. Visually, does Mitch Hedberg’s joke appear to hold here?

```{r exercise-12}
dn_lq %>% 
   filter(state == "TX") %>%
   ggplot(mapping = aes(
   x = longitude,
   y = latitude,
   color = establishment
 )) +
   geom_point(size = 2, alpha = 0.1) + 
   labs(title = "Location of Dennys vs Laquinta in Texas")
```

Interesting. They do seem to cluster more tightly here. Again, hard to know if this is due to anything more than urban - rural differences, but it looks more plausible here at least. It would be helpful to have other establishments to really evaluate this issue. 
